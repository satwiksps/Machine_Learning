{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPNIbz4qCZqiLrD48Z569WM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/satwiksps/Machine_Learning/blob/main/Pipeline_Automation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cEqKMw2FkCXP"
      },
      "outputs": [],
      "source": [
        "#Pima-Indian-Diabetes Dataset\n",
        "from pandas import read_csv\n",
        "url = 'https://raw.githubusercontent.com/erojaso/MLMasteryEndToEnd/master/data/pima-indians-diabetes.data.csv' #Load CSV using Pandas\n",
        "column_names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class'] #Define column names\n",
        "data = read_csv(url, names=column_names) #Load CSV using Pandas\n",
        "array = data.values #Convert to NumPy array\n",
        "X = array[:,0:8] #Split into input column\n",
        "Y = array[:,8] #Split into output column"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "# create pipeline\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('lda', LinearDiscriminantAnalysis()))\n",
        "model = Pipeline(estimators)\n",
        "\n",
        "# evaluate pipeline\n",
        "kfold = KFold(n_splits=10)\n",
        "results = cross_val_score(model, X, Y, cv=kfold)\n",
        "\n",
        "print(results.mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwdq9azhkDuZ",
        "outputId": "8162cc17-2111-4abb-b47c-b19dda8c521c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.773462064251538\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.pipeline import FeatureUnion\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "# create feature union\n",
        "features = []\n",
        "features.append(('pca', PCA(n_components=3)))\n",
        "features.append(('select_best', SelectKBest(k=6)))\n",
        "feature_union = FeatureUnion(features)\n",
        "\n",
        "# create pipeline\n",
        "estimators = []\n",
        "estimators.append(('feature_union', feature_union))\n",
        "estimators.append(('logistic', LogisticRegression(solver='liblinear')))\n",
        "model = Pipeline(estimators)\n",
        "\n",
        "# evaluate pipeline\n",
        "kfold = KFold(n_splits=10)\n",
        "results = cross_val_score(model, X, Y, cv=kfold)\n",
        "\n",
        "print(results.mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6TiapUpkYCn",
        "outputId": "263c695a-5f51-43fd-94e4-6766af5c41b2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7760423786739576\n"
          ]
        }
      ]
    }
  ]
}